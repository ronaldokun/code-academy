{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning I</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando e Carregando Modelos Treinados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo um Grafo Multilayer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs: Este script está compatível com as versões 1.x e 2.x do TensorFlow.\n",
    "# Optamos por manter assim, pois alguns recursos avançados usados neste script ainda não foram implementados no TF 2.\n",
    "\n",
    "# Para executar este script com TF 2, nenhum passo adicional precisa ser feito.\n",
    "# Para executar com TF 1, remova o prefixo tf.compat.v1 ao longo do scriipt e substitua por tf, e comente as linhas abaixo.\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "##########################\n",
    "### Definindo o Modelo\n",
    "##########################\n",
    "\n",
    "# Função que define uma camada\n",
    "def fc_layer(input_tensor,\n",
    "             n_output_units,\n",
    "             name,\n",
    "             activation_fn = None,\n",
    "             seed = None,\n",
    "             weight_params = None,\n",
    "             bias_params = None):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name):\n",
    "\n",
    "        if weight_params is not None:\n",
    "            weights = tf.constant(weight_params, name = 'weights', dtype = tf.float32)\n",
    "        else:\n",
    "            weights = tf.Variable(tf.random.truncated_normal(\n",
    "                shape=[input_tensor.get_shape().as_list()[-1], n_output_units],\n",
    "                    mean = 0.0,\n",
    "                    stddev = 0.1,\n",
    "                    dtype = tf.float32,\n",
    "                    seed = seed),\n",
    "                name = 'weights',)\n",
    "\n",
    "        if bias_params is not None:\n",
    "            biases = tf.constant(bias_params, name = 'biases', dtype=tf.float32)\n",
    "\n",
    "        else:\n",
    "            biases = tf.Variable(tf.zeros(shape = [n_output_units]),\n",
    "                                 name = 'biases',\n",
    "                                 dtype = tf.float32)\n",
    "\n",
    "        act = tf.matmul(input_tensor, weights) + biases\n",
    "\n",
    "        if activation_fn is not None:\n",
    "            act = activation_fn(act)\n",
    "\n",
    "    return act\n",
    "\n",
    "# Função que define o grafo\n",
    "def mlp_graph(n_input = 784,\n",
    "              n_classes = 10,\n",
    "              n_hidden_1 = 128,\n",
    "              n_hidden_2 = 256,\n",
    "              learning_rate = 0.1,\n",
    "              fixed_params = None):\n",
    "\n",
    "    # Carregando pesos e bias de arquivos NumPy\n",
    "    if not fixed_params:\n",
    "        var_names = ['fc1/weights:0', 'fc1/biases:0',\n",
    "                     'fc2/weights:0', 'fc2/biases:0',\n",
    "                     'logits/weights:0', 'logits/biases:0',]\n",
    "\n",
    "        fixed_params = {v: None for v in var_names}\n",
    "        found_params = False\n",
    "    else:\n",
    "        found_params = True\n",
    "\n",
    "    # Input data\n",
    "    tf_x = tf.compat.v1.placeholder(tf.float32, [None, n_input], name = 'features')\n",
    "    tf_y = tf.compat.v1.placeholder(tf.int32, [None], name = 'targets')\n",
    "    tf_y_onehot = tf.one_hot(tf_y, depth = n_classes, name = 'onehot_targets')\n",
    "\n",
    "    # Multilayer perceptron\n",
    "    fc1 = fc_layer(input_tensor = tf_x,\n",
    "                   n_output_units = n_hidden_1,\n",
    "                   name = 'fc1',\n",
    "                   weight_params = fixed_params['fc1/weights:0'],\n",
    "                   bias_params = fixed_params['fc1/biases:0'],\n",
    "                   activation_fn = tf.nn.relu)\n",
    "\n",
    "    fc2 = fc_layer(input_tensor = fc1,\n",
    "                   n_output_units = n_hidden_2,\n",
    "                   name = 'fc2',\n",
    "                   weight_params = fixed_params['fc2/weights:0'],\n",
    "                   bias_params = fixed_params['fc2/biases:0'],\n",
    "                   activation_fn = tf.nn.relu)\n",
    "\n",
    "    logits = fc_layer(input_tensor = fc2,\n",
    "                      n_output_units = n_classes,\n",
    "                      name = 'logits',\n",
    "                      weight_params = fixed_params['logits/weights:0'],\n",
    "                      bias_params = fixed_params['logits/biases:0'],\n",
    "                      activation_fn = tf.nn.relu)\n",
    "\n",
    "    # Loss e optimizer\n",
    "    ### Somente necessário se nenhum parâmetro existente for encontrado\n",
    "    ### e um grafo treinável deve ser inicializado\n",
    "    if not found_params:\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.stop_gradient(tf_y_onehot))\n",
    "        cost = tf.reduce_mean(input_tensor=loss, name='cost')\n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n",
    "            learning_rate=learning_rate)\n",
    "        train = optimizer.minimize(cost, name='train')\n",
    "\n",
    "    # Previsões\n",
    "    probabilities = tf.nn.softmax(logits, name = 'probabilities')\n",
    "    labels = tf.cast(tf.argmax(input=logits, axis=1), tf.int32, name = 'labels')\n",
    "\n",
    "    correct_prediction = tf.equal(labels, tf_y, name='correct_predictions')\n",
    "    accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, tf.float32), name = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Salvando o Modelo Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import input_data\n",
    "\n",
    "##########################\n",
    "### Configurações\n",
    "##########################\n",
    "\n",
    "# Hiperparâmetros\n",
    "learning_rate = 0.1\n",
    "training_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "##########################\n",
    "### Definição do Grafo\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    mlp_graph()\n",
    "\n",
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/media/datasets/DeepLearningI/Cap04/MNIST\", one_hot = False)\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = False)\n",
    "\n",
    "\n",
    "##########################\n",
    "### Treinamento e Avaliação\n",
    "##########################\n",
    "\n",
    "with tf.compat.v1.Session(graph = g) as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    saver0 = tf.compat.v1.train.Saver()\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run(['train', 'cost:0'], feed_dict = {'features:0': batch_x,\n",
    "                                                            'targets:0': batch_y})\n",
    "            avg_cost += c\n",
    "\n",
    "        train_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.train.images,\n",
    "                                                        'targets:0': mnist.train.labels})\n",
    "\n",
    "        valid_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.validation.images,\n",
    "                                                        'targets:0': mnist.validation.labels})\n",
    "\n",
    "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / (i + 1)), end=\"\")\n",
    "        print(\" | Acurácia em Treino/Validação: %.3f/%.3f\" % (train_acc, valid_acc))\n",
    "\n",
    "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,\n",
    "                                                   'targets:0': mnist.test.labels})\n",
    "    print('Acurácia em Teste: %.3f' % test_acc)\n",
    "\n",
    "    ##########################\n",
    "    ### Salvando o Modelo Treinado\n",
    "    ##########################\n",
    "    saver0.save(sess, save_path = './mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recarregando o Modelo de Arquivos Meta e Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import input_data\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/media/datasets/DeepLearningI/Cap04/MNIST\", one_hot = False)\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = False)\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "\n",
    "    saver1 = tf.compat.v1.train.import_meta_graph('./mlp.meta')\n",
    "    saver1.restore(sess, save_path = './mlp')\n",
    "\n",
    "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,\n",
    "                                                   'targets:0': mnist.test.labels})\n",
    "    print('Acurácia em Teste: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com Arquivos NumPy e Criando Grafos Não-Treinados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando os Parâmetros do Modelo Para Arquivos NumPy NPZ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "\n",
    "    saver1 = tf.compat.v1.train.import_meta_graph('./mlp.meta')\n",
    "    saver1.restore(sess, save_path='./mlp')\n",
    "\n",
    "    var_names = [v.name for v in\n",
    "                 tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES)]\n",
    "\n",
    "    params = {}\n",
    "    print('Variáveis encontradas:')\n",
    "    for v in var_names:\n",
    "        print(v)\n",
    "\n",
    "        ary = sess.run(v)\n",
    "        params[v] = ary\n",
    "\n",
    "    np.savez('mlp', **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando Arquivos NumPy .npz em `mlp_graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import input_data\n",
    "\n",
    "###########################\n",
    "### Carregando Dados e Parâmetros\n",
    "###########################\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/media/datasets/DeepLearningI/Cap04/MNIST\", one_hot = False)\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = False)\n",
    "param_dict = np.load('mlp.npz')\n",
    "\n",
    "##########################\n",
    "### Definição do Grafo\n",
    "##########################\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "\n",
    "    mlp_graph(fixed_params = param_dict)\n",
    "\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "\n",
    "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,'targets:0': mnist.test.labels})\n",
    "    print('Acurácia em Teste: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
