{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Deep Learning I</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação com TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compreendendo o Dataset\n",
    "\n",
    "MNIST é um dataset que contém 70.000 imagens rotuladas de dígitos escritos à mão, conforme imagem abaixo.\n",
    "\n",
    "![MNIST Data Sample](mnist-sample.png \"MNIST Data Sample\")\n",
    "\n",
    "Nós vamos treinar um classificador linear em uma parte desse conjunto de dados e depois testar o classificador contra outra parte do conjunto de dados para avaliar a performance do nosso modelo. Para isso usaremos um modelo Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Importando os Módulos\n",
    "##########################\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import input_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.cmap'] = 'Greys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs: Este script está compatível com as versões 1.x e 2.x do TensorFlow.\n",
    "# Optamos por manter assim, pois alguns recursos avançados usados neste script ainda não foram implementados no TF 2.\n",
    "\n",
    "# Para executar este script com TF 2, nenhum passo adicional precisa ser feito.\n",
    "# Para executar com TF 1, remova o prefixo tf.compat.v1 ao longo do scriipt e substitua por tf, e comente as 3 linhas abaixo.\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "mnist = input_data.read_data_sets(\"/media/datasets/DeepLearningI/Cap04/MNIST\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse procedimento já divide o conjunto de dados em três partes:\n",
    "\n",
    "* Dataset de treino (55000 exemplos) usado para treinar o modelo\n",
    "* Dataset de validação (5000 exemplos) usado para otimizar os hiperparâmetros \n",
    "* Dataset de test (10000 exemplos) usado para avaliar a precisão do modelo treinado\n",
    "\n",
    "As imagens estão em escala de cinza e cada uma tem dimensão de 28 pixels de largura por 28 pixels de altura sendo armazenada em uma matriz de comprimento 784.\n",
    "\n",
    "Os rótulos (labels) são um vetor * one hot * de comprimento 10, o que significa que é um vetor preenchido com zeros, exceto no local que corresponde ao rótulo a que se refere. Por exemplo. Uma imagem com label `3` será representada como `(0, 0, 0, 1, 0, 0, 0, 0, 0, 0)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (mnist.train.images.shape)\n",
    "print (mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (mnist.validation.images.shape)\n",
    "print (mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (mnist.test.images.shape)\n",
    "print (mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5480f2550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "### Visualizando os Dados\n",
    "##########################\n",
    "example_image = mnist.train.images[1]\n",
    "example_image_reshaped = example_image.reshape((28, 28))\n",
    "example_label = mnist.train.labels[1]\n",
    "\n",
    "print (example_label)\n",
    "plt.imshow(example_image_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura da Rede\n",
    "\n",
    "Agora que compreendemos melhor o conjunto de dados com o qual estamos trabalhando, vamos passar para os bits de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Configurações\n",
    "##########################\n",
    "\n",
    "# Hiperparâmetros\n",
    "learning_rate = 0.1\n",
    "training_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Arquitetura\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "n_input = 784\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo o Grafo Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, configuramos alguns espaços reservados (placeholders) para armazenar lotes desses dados de treinamento para quando treinarmos nosso modelo. A razão pela qual trabalhamos em lotes é que é mais fácil carregar na memória do que usar todo o conjunto. E é essa noção de trabalhar com lotes (aleatórios) de entrada ao invés de todo o conjunto que nos move do domínio de * Gradient Descent * que vimos anteriormente, para * Stochastic Gradient Descent * que temos aqui. Depois criamos as camadas, a função de perda e como vamos calcular as previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiremos a inicialização de pesos e bias da seguinte forma:\n",
    "\n",
    "````\n",
    "W1 = tf.Variable(tf.zeros([784, 100]))\n",
    "b1 = tf.Variable(tf.zeros([100]))\n",
    "W2 = tf.Variable(tf.zeros([100, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "````\n",
    "\n",
    "Definimos também a nossa função de perda para medir a performance do modelo em imagens com rótulos conhecidos. Usamos a forma específica chamada de[cross entropy loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Definição do Grafo no TensorFlow\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "\n",
    "    # Input data\n",
    "    tf_x = tf.compat.v1.placeholder(tf.float32, [None, n_input], name = 'features')\n",
    "    tf_y = tf.compat.v1.placeholder(tf.float32, [None, n_classes], name = 'targets')\n",
    "\n",
    "    # Parâmetros do Modelo\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random.truncated_normal([n_input, n_hidden_1], stddev = 0.1)),\n",
    "        'w2': tf.Variable(tf.random.truncated_normal([n_hidden_1, n_hidden_2], stddev = 0.1)),\n",
    "        'out': tf.Variable(tf.random.truncated_normal([n_hidden_2, n_classes], stddev = 0.1))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "\n",
    "    # Multilayer perceptron\n",
    "    layer_1 = tf.add(tf.matmul(tf_x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "\n",
    "    # Loss e optimizer\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits = out_layer, labels = tf.stop_gradient( tf_y))\n",
    "    cost = tf.reduce_mean(input_tensor=loss, name = 'cost')\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "    train = optimizer.minimize(cost, name = 'train')\n",
    "\n",
    "    # Previsões\n",
    "    correct_prediction = tf.equal(tf.argmax(input=tf_y, axis=1), tf.argmax(input=out_layer, axis=1))\n",
    "    accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, tf.float32), name = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo\n",
    "\n",
    "De acordo com o funcionamento do TensorFlow, nós realmente não executamos nenhum dos códigos acima no sentido clássico. Tudo o que fizemos foi definir o que é chamado de grafo computacional.\n",
    "\n",
    "Agora, vamos em frente e inicializamos uma sessão para realmente treinar o modelo e avaliar seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | AvgCost: 0.348 | Acurácia em Treino/Validação: 0.933/0.936\n",
      "Epoch: 002 | AvgCost: 0.166 | Acurácia em Treino/Validação: 0.962/0.959\n",
      "Epoch: 003 | AvgCost: 0.120 | Acurácia em Treino/Validação: 0.972/0.968\n",
      "Epoch: 004 | AvgCost: 0.094 | Acurácia em Treino/Validação: 0.980/0.974\n",
      "Epoch: 005 | AvgCost: 0.077 | Acurácia em Treino/Validação: 0.982/0.973\n",
      "Epoch: 006 | AvgCost: 0.064 | Acurácia em Treino/Validação: 0.985/0.976\n",
      "Epoch: 007 | AvgCost: 0.054 | Acurácia em Treino/Validação: 0.987/0.975\n",
      "Epoch: 008 | AvgCost: 0.046 | Acurácia em Treino/Validação: 0.988/0.976\n",
      "Epoch: 009 | AvgCost: 0.038 | Acurácia em Treino/Validação: 0.992/0.977\n",
      "Epoch: 010 | AvgCost: 0.033 | Acurácia em Treino/Validação: 0.992/0.977\n",
      "Acurácia em Teste: 0.975\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### Treinamento e Avaliação\n",
    "##########################\n",
    "\n",
    "with tf.compat.v1.Session(graph = g) as sess:\n",
    "\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run(['train', 'cost:0'], feed_dict = {'features:0': batch_x,\n",
    "                                                              'targets:0': batch_y})\n",
    "            avg_cost += c\n",
    "\n",
    "        train_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.train.images,\n",
    "                                                        'targets:0': mnist.train.labels})\n",
    "\n",
    "        valid_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.validation.images,\n",
    "                                                        'targets:0': mnist.validation.labels})\n",
    "\n",
    "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / (i + 1)), end=\"\")\n",
    "        print(\" | Acurácia em Treino/Validação: %.3f/%.3f\" % (train_acc, valid_acc))\n",
    "\n",
    "    test_acc = sess.run(accuracy, feed_dict = {'features:0': mnist.test.images,\n",
    "                                               'targets:0': mnist.test.labels})\n",
    "\n",
    "    print('Acurácia em Teste: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "737b3e0e8750f89ce31674571febe5a5a08e902b32bb8cbee589bdf91ca77e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
