{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning I</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando CNNs Para Reconhecimento da Posição dos Olhos em Fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 1) Localizando a posição dos olhos\n",
    "\n",
    "Parte 2) Segmentação da face em regiões de interesse \n",
    "\n",
    "Dataset: https://www.bioid.com/About/BioID-Face-Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se a GPU tem memória disponível\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from random import randint\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as variáveis que receberão as coordenadas dos olhos e criando um array preenchido com zeros\n",
    "\n",
    "lx=[]\n",
    "ly=[]\n",
    "rx=[]\n",
    "ry=[]\n",
    "\n",
    "# Reshape das imagens em 180 x 180\n",
    "images_orig = np.ndarray(shape = (1521,180,180,1), dtype = np.float32)\n",
    "print(images_orig)\n",
    "\n",
    "i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Dataset\n",
    "\n",
    "https://www.bioid.com/About/BioID-Face-Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirnames, filenames in os.walk(\"/media/datasets/DeepLearningI/Cap09/BioID-FaceDatabase\"):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(pgm)$\", filename):  # Buscando pelos arquivos de imagem\n",
    "            \n",
    "            # Coleta caminho dos arquivos\n",
    "            filepath = os.path.join(root, filename)\n",
    "            \n",
    "            # Localizando as imagens\n",
    "            image = (load_img(str(filepath.split(\".\")[0]+\".pgm\"))) \n",
    "\n",
    "            # Crop das imagens para escala left, top, right, bottom\n",
    "            image = image.crop((102,0,282,180))  \n",
    "            \n",
    "            # Reconverte as imagens para esclaa de cinza\n",
    "            image=ImageOps.grayscale(image)  \n",
    "            \n",
    "            # Converte imagens em arrays\n",
    "            image = img_to_array(image)  \n",
    "            \n",
    "            # Append imagem ao numpy array\n",
    "            images_orig[i] = image   \n",
    "            print(images_orig)\n",
    "\n",
    "            # Coleta os arquivos .eye que contém as coordeandas da posição dos olhos\n",
    "            f = open(str(filepath.split(\".\")[0]+\".eye\"),mode=\"r\")  \n",
    "            for line in islice(f,1,2):\n",
    "                label = list(map(int, line.split()))  \n",
    "            lx.append(label[0]-102)\n",
    "            ly.append(label[1])\n",
    "            rx.append(label[2]-102)\n",
    "            ry.append(label[3])\n",
    "            f.close()\n",
    "            i += 1\n",
    "            if i % 250 == 0:\n",
    "                print(\"%d imagens no array\" % i)\n",
    "    print(\"Todas as imagens no array!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print do resultado da carga de dados\n",
    "\n",
    "for i in range (0,10):\n",
    "    fig,ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    index=randint(0,1500)\n",
    "    ax.imshow(images_orig[index].reshape(180,180),cmap='gray') \n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    rect1 = patches.Rectangle((rx[index],ry[index]),2,2,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    rect2 = patches.Rectangle((lx[index],ly[index]),2,2,linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect1)\n",
    "    ax.add_patch(rect2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, normalizamos nossos dados e preparamos para alimentar nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_orig = images_orig/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exigimos que nossas variáveis de saída estejam entre 0 e 1 para serem alimentadas em nosso modelo. Isso é para garantir que nossos pesos do modelo não explodem durante o backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando coordenadas individuais usando min-max scaler\n",
    "rx=np.asarray(rx)\n",
    "rx_max=rx.max()\n",
    "rx_min=rx.min()\n",
    "rx=(rx-rx_min)/(rx_max-rx_min)\n",
    "\n",
    "ry=np.asarray(ry)\n",
    "ry_max=ry.max()\n",
    "ry_min=ry.min()\n",
    "ry=(ry-ry_min)/(ry_max-ry_min)\n",
    "\n",
    "lx=np.asarray(lx)\n",
    "lx_max=lx.max()\n",
    "lx_min=lx.min()\n",
    "lx=(lx-lx_min)/(lx_max-lx_min)\n",
    "\n",
    "ly=np.asarray(ly)\n",
    "ly_max=ly.max()\n",
    "ly_min=ly.min()\n",
    "ly=(ly-ly_min)/(ly_max-ly_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, dividimos nossos dados em conjunto de treino e teste, usamos as primeiras 900 imagens para treinar nosso modelo e usaremos o resto das imagens para testar nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=images_orig[0:900]\n",
    "X_test=images_orig[900:1200]\n",
    "\n",
    "# Reshape dos dados para que estejam compatíveis com o TensorFlow\n",
    "X_train=X_train.reshape(900,1,180,180)\n",
    "X_test=X_test.reshape(300,1,180,180)\n",
    "\n",
    "rx_train=rx[0:900]\n",
    "rx_test=rx[900:1200]\n",
    "\n",
    "ry_train=ry[0:900]\n",
    "ry_test=ry[900:1200]\n",
    "\n",
    "lx_train=lx[0:900]\n",
    "lx_test=lx[900:1200]\n",
    "\n",
    "ly_train=ly[0:900]\n",
    "ly_test=ly[900:1200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, definimos nosso modelo.\n",
    "\n",
    "Usaremos os seguintes parâmetros para treinar nosso modelo.\n",
    "\n",
    "* batch size = 32 - os pesos serão atualizados após 32 amostras\n",
    "* number epochs = 50 - vamos treinar nosso algoritmo para 50 iterações \n",
    "* kernel size = 3 - nós usaremos kernels (filtros) 3 x 3 \n",
    "* pool size = 2 - usaremos pooling 2x2 \n",
    "* convolutional layer 1 depth = 32  \n",
    "* convolutional layer 2 depth = 64  \n",
    "* convolutional layer 3 depth = 128  \n",
    "* dropout 1= 0.25 - dropout depois da camada de pooling com probabilidade 0.25  \n",
    "* dropout 2 = 0.5 - dropout na camada FC layer com probabilidade 0.5  \n",
    "* hidden layer 1 = 256  - a primeira camada totalmente conectada terá 256 neurônios\n",
    "* hidden layer 2 = 512  - a segunda camada totalmente conectada terá 512 neurônios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "num_epochs = 50 \n",
    "kernel_size = 3\n",
    "pool_size = 2 \n",
    "conv_depth_1 = 32 \n",
    "conv_depth_2 = 64 \n",
    "conv_depth_3 = 128\n",
    "drop_prob_1 = 0.25 \n",
    "drop_prob_2 = 0.5 \n",
    "hidden_size1 = 256 \n",
    "hidden_size2 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape para a camada de entrada no TensorFlow\n",
    "inp = Input(shape = (1,180,180))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura da Primeira Camada Convolucional\n",
    "\n",
    "Conv_32 -> Conv_32 -> Pool_2x2 -> dropout_0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = Convolution2D(conv_depth_1,\n",
    "                       (kernel_size, kernel_size),\n",
    "                       kernel_initializer='glorot_normal', \n",
    "                       padding='same', \n",
    "                       activation='relu')\n",
    "\n",
    "conv_2 = Convolution2D(conv_depth_1, \n",
    "                       (kernel_size, kernel_size), \n",
    "                       padding='same', \n",
    "                       activation='relu')\n",
    "\n",
    "pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))\n",
    "\n",
    "drop_1 = Dropout(drop_prob_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura da Segunda Camada Convolucional\n",
    "\n",
    "Conv_64 -> Conv_64 -> Pool_2x2 -> dropout_0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3 = Convolution2D(conv_depth_2, \n",
    "                       (kernel_size, kernel_size), \n",
    "                       padding='same', \n",
    "                       activation='relu')\n",
    "\n",
    "conv_4 = Convolution2D(conv_depth_2, \n",
    "                       (kernel_size, kernel_size), \n",
    "                       padding='same', \n",
    "                       activation='relu')\n",
    "\n",
    "pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))\n",
    "drop_2 = Dropout(drop_prob_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura da Terceira Camada Convolucional\n",
    "\n",
    "Conv_128 -> Conv_128 -> Pool_2x2 -> dropout_0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_5 = Convolution2D(conv_depth_3, \n",
    "                       (kernel_size, kernel_size), \n",
    "                       padding='same', \n",
    "                       activation='relu')\n",
    "\n",
    "conv_6 = Convolution2D(conv_depth_3, \n",
    "                       (kernel_size, kernel_size), \n",
    "                       padding='same', \n",
    "                       activation='relu')\n",
    "\n",
    "pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))\n",
    "\n",
    "drop_3 = Dropout(drop_prob_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camadas Totalmente Conectadas\n",
    "\n",
    "Flatten -> Hidden_256 -> dropout_1 -> Hidden_512 -> dropout_2 ->Dense [Output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = Flatten()\n",
    "hidden = Dense(hidden_size1, activation='relu')\n",
    "hidden1 = Dense(hidden_size2, activation='relu')\n",
    "drop_3 = Dropout(drop_prob_2)\n",
    "out1 = Dense(1)\n",
    "out2 = Dense(1)\n",
    "out3 = Dense(1)\n",
    "out4 = Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para definir um modelo, basta especificar suas camadas de entrada e saída\n",
    "model = Model(inputs = inp, outputs = [out1,out2,out3,out4]) \n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando o modelo\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early-stopping\n",
    "early_stop =  EarlyStopping(monitor = 'loss', min_delta = 0.001, patience = 5, verbose = 1, mode = 'min')\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit do modelo\n",
    "model.fit(X_train,\n",
    "          [lx_train,ly_train,rx_train,ry_train],\n",
    "          batch_size = batch_size, \n",
    "          epochs = num_epochs, \n",
    "          callbacks = callbacks,\n",
    "          verbose = 1, \n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões\n",
    "\n",
    "for i in range (0,10):\n",
    "    lx_p=0\n",
    "    ly_p=0\n",
    "    rx_p=0\n",
    "    ry_p=0\n",
    "    index = randint(0,299)\n",
    "    lx_p,ly_p,rx_p,ry_p = model.predict(X_test[index].reshape(1,1,180,180))\n",
    "    lx_p=lx_p*(lx_max-lx_min)+lx_min\n",
    "    ly_p=ly_p*(ly_max-ly_min)+ly_min\n",
    "    rx_p=rx_p*(rx_max-rx_min)+rx_min\n",
    "    ry_p=ry_p*(ry_max-ry_min)+ry_min\n",
    "    \n",
    "    display_img=X_test[index]*255.0\n",
    "    \n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(display_img.reshape(180,180),cmap='gray') \n",
    "\n",
    "    rect1 = patches.Rectangle((lx_p,ly_p),2,2,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    rect2 = patches.Rectangle((rx_p,ry_p),2,2,linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "    ax.add_patch(rect1)\n",
    "    ax.add_patch(rect2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desempenho do modelo no conjunto de testes, não foi tão preciso, indicando que devemos ajustar o modelo, modificando os hiperparâmetros ou alterando a arquitetura do modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o modelo em fomato JSON e os pesos em formato HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"modelo.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Salvando o modelo no formato HDF5\n",
    "model.save_weights(\"modelo.h5\")\n",
    "print(\"Modelo salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
