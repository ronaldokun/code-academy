{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning I</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo Um Algoritmo Para Rede Neural Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As redes neurais recebem entradas e produzem saídas e elas podem melhorar a precisão de suas saídas ao longo do tempo. Para explorar este conceito, vamos implementar primeiro um nó mais complicado (e mais útil!) do que o nó Add: o nó Linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como já vimos anteriormente, um neurônio artificial depende de 3 componentes: input x (vetor), pesos w (vetor) e bias b (escalar). O output do neurônio é a soma ponderada dos pesos com inputs, mais o bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao variar os pesos, você pode variar a quantidade de influência que qualquer entrada dada tenha na saída. O aspecto de aprendizagem das redes neurais ocorre durante um processo conhecido como backpropagation. Em backpropogation, a rede modifica os pesos para melhorar a precisão da saída da rede. Vamos chegar lá!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o resto deste notebook, indicaremos x como X e w como W, pois agora serão matrizes, e b agora será um vetor em vez de um escalar. Considere um nó linear com 1 entrada e k saídas (mapeando 1 entrada para k saídas). Neste contexto, um input / output é sinônimo de um atributo (feature). Vamos ilustrar isso para ficar mais claro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"MLP03-01.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'MLP03-01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos np.array para criar as matrizes e vetores. E usaremos np.dot, que funciona como multiplicação de matriz para matrizes 2D, para multiplicar as matrizes de entrada e pesos. Também vale a pena notar que numpy realmente sobrecarrega o operador __add__ para que você possa usá-lo diretamente com np.array (por exemplo, np.array () + np.array ())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuronio:\n",
    "    def __init__(self, nodes_entrada = []):\n",
    "        self.nodes_entrada = nodes_entrada\n",
    "        self.nodes_saida = []\n",
    "        self.valor = None\n",
    "        for n in nodes_entrada:\n",
    "            n.nodes_saida.append(self)\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Neuronio):\n",
    "    def __init__(self):\n",
    "        Neuronio.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear(Neuronio):\n",
    "    def __init__(self, X, W, b):\n",
    "        # Observe a ordem que os parâmetros são passados para o construtor (função init da Classe Neuronio)\n",
    "        Neuronio.__init__(self, [X, W, b])\n",
    "\n",
    "    def forward(self):\n",
    "        X = self.nodes_entrada[0].valor\n",
    "        W = self.nodes_entrada[1].valor\n",
    "        b = self.nodes_entrada[2].valor\n",
    "        self.valor = np.dot(X, W) + b\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Classifica os nós em ordem topológica usando o Algoritmo de Kahn.\n",
    "\n",
    "    `Feed_dict`: um dicionário em que a chave é um nó ` Input` e o valor é o respectivo feed de valor para esse nó.\n",
    "\n",
    "    Retorna uma lista de nós ordenados.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.nodes_saida:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.valor = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.nodes_saida:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_node, sorted_nodes):\n",
    "    \"\"\"\n",
    "   Executa uma passagem para a frente através de uma lista de nós ordenados.\n",
    "\n",
    "     Argumentos:\n",
    "\n",
    "         `Output_node`: Um nó no grafo, deve ser o nó de saída.\n",
    "         `Sorted_nodes`: uma lista topologicamente ordenada de nós.\n",
    "\n",
    "     Retorna o valor do Nó de saída\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_nodes:\n",
    "        n.forward()\n",
    "\n",
    "    return output_node.valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executando o Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-13.  11.]\n",
      " [-22.  17.]]\n"
     ]
    }
   ],
   "source": [
    "# Este script cria e executa o grafo \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Parâmetros de entrada\n",
    "inputs, weights, bias = Input(), Input(), Input()\n",
    "\n",
    "# Função Linear\n",
    "f = Linear(inputs, weights, bias)\n",
    "\n",
    "# Atribuindo valores aos parâmetros\n",
    "x = np.array([[-2., -1.], [-2, -4]])\n",
    "w = np.array([[4., -6], [3., -2]])\n",
    "b = np.array([-2., -3])\n",
    "\n",
    "# Define o feed_dict\n",
    "feed_dict = {inputs: x, weights: w, bias: b}\n",
    "\n",
    "# Ordena as entradas para execução\n",
    "graph = topological_sort(feed_dict)\n",
    "\n",
    "# Gera o output com o forward_pass\n",
    "output = forward_pass(f, graph)\n",
    "\n",
    "# Print\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
