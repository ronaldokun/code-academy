{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Processamento de Linguagem Natural</font>\n",
    "\n",
    "\n",
    "## Mini-Projeto 3\n",
    "### Reconhecimento da Fala - Detectando Emoções em Arquivos de Áudio com Inteligência Artificial\n",
    "### Parte 3 - Detecção e Classificação de Emoções em Arquivos de Áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.7.6\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um Mini-Projeto especial. \n",
    "\n",
    "Vamos trabalhar com uma das tarefas mais complexas em Inteligência Artificial: extrair emoções a partir da voz em arquivos de áudio.\n",
    "\n",
    "Detectar emoções é uma das estratégias de Marketing mais importantes no mundo de hoje. Você pode personalizar aplicações para fornecer tratamentos diferentes para um indivíduo de acordo com a emoção detectada na voz de uma pessoa. Esse tipo de aplicação é um dos pilares para uma solução completa de IA.\n",
    "\n",
    "Alguns exemplos de aplicações desse tipo de solução, incluem:\n",
    "\n",
    "- Uma central de atendimento que toca músicas diferentes de acordo com a emoção detectada na voz do cliente. \n",
    "\n",
    "- Um carro autônomo que desacelera quando alguém está com raiva ou com medo. \n",
    "\n",
    "- Assistente pessoal que reage de acordo com a emoção detectada na voz.\n",
    "\n",
    "- Aplicações de Marketing que oferecem diferentes produtos ou opções de acordo com a emoção do cliente.\n",
    "\n",
    "- Assistente Virtual, que pode ser uma Enfermeira Virtual ou mesmo um Professor de Inglês, e que reage de acordo com a voz do interlocutor.\n",
    "\n",
    "Entre outros exemplos.\n",
    "\n",
    "Usaremos a biblioteca Librosa em Python para processar e extrair recursos dos arquivos de áudio. Librosa é um pacote Python para análise de música e áudio. Ele fornece os componentes necessários para criar sistemas de recuperação de informações musicais. \n",
    "\n",
    "Usando a biblioteca librosa, conseguimos extrair recursos através do MFCC (Mel Frequency Cepstral Coefficient). Os MFCCs são coeficientes amplamente usado no reconhecimento automático de fala. \n",
    "\n",
    "Também separamos a voz de mulheres e homens usando os identificadores fornecidos no dataset, como forma de deixar o modelo de reconhecimento de voz ainda mais preciso e personalizado.\n",
    "\n",
    "Cada arquivo de áudio fornece muitos recursos, que são basicamente uma matriz de muitos valores. A esses recursos, iremos atribuir rótulos especificando o gênero da voz no áudio e a emoção detectada.\n",
    "\n",
    "Como este projeto é um grande esforço de trabalho, ele foi dividido em 3 partes:\n",
    "\n",
    "- **Parte 1 - Preparação dos Dados, Treinamento e Avaliação do Detector de Emoções com Machine Learning**\n",
    "- **Parte 2 - Preparação dos Dados, Treinamento e Avaliação do Detector de Emoções com Deep Learning**\n",
    "- **Parte 3 - Detecção e Classificação de Emoções em Arquivos de Áudio**\n",
    "\n",
    "Este projeto pode ser facilmente adaptado aos seus próprios projetos. Tudo que você precisa é providenciar arquivos de áudio gravados com pessoas com diferentes emoções. Usaremos um dataset público para nosso trabalho.\n",
    "\n",
    "Esta é a Parte 3. Aprenda e divirta-se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o pyaudio\n",
    "!pip install -q pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import wave\n",
    "import pyaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas  1.1.4\n",
      "sklearn 0.23.2\n",
      "numpy   1.19.3\n",
      "pyaudio 0.2.11\n",
      "librosa 0.7.2\n",
      "Data Science Academy\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos um arquivo de áudio\n",
    "X, sample_rate = librosa.load('arquivos/03-02-06-02-02-02-24.wav', \n",
    "                              res_type = 'kaiser_fast',\n",
    "                              duration = 3,\n",
    "                              sr = 22050*2,\n",
    "                              offset = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertemos a sample rate para array NumPy\n",
    "sample_rate = np.array(sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos o modelo pré-treinado\n",
    "model = load_model('modelos/detecta_emotion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos o otimizador\n",
    "opt = RMSprop(lr = 0.0001, decay = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos o modelo\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos o encoder para o novo arquivo de áudio carregado anteriormente\n",
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamos as classes\n",
    "lb.classes_ = np.load('labels/label_classes.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraímos as features\n",
    "features = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "features_df= pd.DataFrame(data=features)\n",
    "features_stacked = features_df.stack().to_frame().T\n",
    "features_expanded= np.expand_dims(features_stacked, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 761us/step\n"
     ]
    }
   ],
   "source": [
    "# Fazemos as previsões com o modelo treinado\n",
    "predictions = model.predict(features_expanded, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtemos a previsão de maior probabilidade\n",
    "predictions_mod = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertemos para inteiro\n",
    "preds_flat = predictions_mod.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos com o encoder\n",
    "predictions_array = (lb.inverse_transform((preds_flat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female_fearful'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aqui está a previsão do nosso modelo para o arquivo de áudio\n",
    "predictions_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use outros arquivos de áudio e teste a aplicação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
