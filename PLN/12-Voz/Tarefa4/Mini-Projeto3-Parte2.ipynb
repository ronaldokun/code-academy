{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Processamento de Linguagem Natural</font>\n",
    "\n",
    "\n",
    "## Mini-Projeto 3\n",
    "### Reconhecimento da Fala - Detectando Emoções em Arquivos de Áudio com Inteligência Artificial\n",
    "### Parte 2 - Preparação dos Dados, Treinamento e Avaliação do Detector de Emoções com Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Este jupyter notebook leva um bom tempo para ser executado. Se preferir, você pode apenas estudar este jupyter notebook e na Parte 3 o modelo será fornecido a você treinado e funcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um Mini-Projeto especial. \n",
    "\n",
    "Vamos trabalhar com uma das tarefas mais complexas em Inteligência Artificial: extrair emoções a partir da voz em arquivos de áudio.\n",
    "\n",
    "Detectar emoções é uma das estratégias de Marketing mais importantes no mundo de hoje. Você pode personalizar aplicações para fornecer tratamentos diferentes para um indivíduo de acordo com a emoção detectada na voz de uma pessoa. Esse tipo de aplicação é um dos pilares para uma solução completa de IA.\n",
    "\n",
    "Alguns exemplos de aplicações desse tipo de solução, incluem:\n",
    "\n",
    "- Uma central de atendimento que toca músicas diferentes de acordo com a emoção detectada na voz do cliente. \n",
    "\n",
    "- Um carro autônomo que desacelera quando alguém está com raiva ou com medo. \n",
    "\n",
    "- Assistente pessoal que reage de acordo com a emoção detectada na voz.\n",
    "\n",
    "- Aplicações de Marketing que oferecem diferentes produtos ou opções de acordo com a emoção do cliente.\n",
    "\n",
    "- Assistente Virtual, que pode ser uma Enfermeira Virtual ou mesmo um Professor de Inglês, e que reage de acordo com a voz do interlocutor.\n",
    "\n",
    "Entre outros exemplos.\n",
    "\n",
    "Usaremos a biblioteca Librosa em Python para processar e extrair recursos dos arquivos de áudio. Librosa é um pacote Python para análise de música e áudio. Ele fornece os componentes necessários para criar sistemas de recuperação de informações musicais. \n",
    "\n",
    "Usando a biblioteca librosa, conseguimos extrair recursos através do MFCC (Mel Frequency Cepstral Coefficient). Os MFCCs são coeficientes amplamente usado no reconhecimento automático de fala. \n",
    "\n",
    "Também separamos a voz de mulheres e homens usando os identificadores fornecidos no dataset, como forma de deixar o modelo de reconhecimento de voz ainda mais preciso e personalizado.\n",
    "\n",
    "Cada arquivo de áudio fornece muitos recursos, que são basicamente uma matriz de muitos valores. A esses recursos, iremos atribuir rótulos especificando o gênero da voz no áudio e a emoção detectada.\n",
    "\n",
    "Como este projeto é um grande esforço de trabalho, ele foi dividido em 3 partes:\n",
    "\n",
    "- **Parte 1 - Preparação dos Dados, Treinamento e Avaliação do Detector de Emoções com Machine Learning**\n",
    "- **Parte 2 - Preparação dos Dados, Treinamento e Avaliação do Detector de Emoções com Deep Learning**\n",
    "- **Parte 3 - Detecção e Classificação de Emoções em Arquivos de Áudio**\n",
    "\n",
    "Este projeto pode ser facilmente adaptado aos seus próprios projetos. Tudo que você precisa é providenciar arquivos de áudio gravados com pessoas com diferentes emoções. Usaremos um dataset público para nosso trabalho.\n",
    "\n",
    "Esta é a Parte 2. Aprenda e divirta-se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala pacote librosa\n",
    "!pip install -q librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.pyplot import specgram\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, AveragePooling1D, BatchNormalization, Input, Flatten, Dropout, Activation\n",
    "from keras.utils import to_categorical, np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um classe para o plot durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para o plot durante o treinamento\n",
    "class LivePlot(keras.callbacks.Callback):\n",
    "    \n",
    "    # Função usada no começo do treinamento\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # Função usada no fim do treinamento\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        # Antes de plotar, certifique-se de que pelo menos 2 épocas tenham passado\n",
    "        if len(self.losses) > 1:\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            plt.style.use(\"seaborn\")\n",
    "            \n",
    "            # Plot \n",
    "            plt.figure()\n",
    "            plt.plot(N, self.losses, label = \"train_loss\")\n",
    "            plt.plot(N, self.acc, label = \"train_acc\")\n",
    "            plt.plot(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.plot(N, self.val_acc, label = \"val_acc\")\n",
    "            plt.title(\"Acurácia e Erro de Treinamento na [Epoch {}]\".format(epoch))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Acurácia e Erro\")\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe abaixo será usada para mapear os sentimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para mapear os sentimentos\n",
    "class FetchLabel():\n",
    "\n",
    "    def get_emotion(self, file_path):\n",
    "        item = file_path.split('/')[-1]\n",
    "        if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "            return 'female_calm'\n",
    "        elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "            return 'male_calm'\n",
    "        elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "            return 'female_happy'\n",
    "        elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "            return 'male_happy'\n",
    "        elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "            return 'female_sad'\n",
    "        elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "            return 'male_sad'\n",
    "        elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "            return 'female_angry'\n",
    "        elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "            return 'male_angry'\n",
    "        elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "            return 'female_fearful'\n",
    "        elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "            return 'male_fearful'\n",
    "        elif item[6:-16]=='01' and int(item[18:-4])%2==0:\n",
    "            return 'female_neutral'\n",
    "        elif item[6:-16]=='01' and int(item[18:-4])%2==1:\n",
    "            return 'male_neutral'\n",
    "        elif item[6:-16]=='07' and int(item[18:-4])%2==0:\n",
    "            return 'female_disgusted'\n",
    "        elif item[6:-16]=='07' and int(item[18:-4])%2==1:\n",
    "            return 'male_disgusted'\n",
    "        elif item[6:-16]=='08' and int(item[18:-4])%2==0:\n",
    "            return 'female_surprised'\n",
    "        elif item[6:-16]=='08' and int(item[18:-4])%2==1:\n",
    "            return 'male_surprised'\n",
    "        elif item[:1]=='a':\n",
    "            return 'male_angry'\n",
    "        elif item[:1]=='f':\n",
    "            return 'male_fearful'\n",
    "        elif item[:1]=='h':\n",
    "            return 'male_happy'\n",
    "        elif item[:1]=='n':\n",
    "            return 'male_neutral'\n",
    "        elif item[:2]=='sa':\n",
    "            return 'male_sad'\n",
    "        elif item[:1]=='d':\n",
    "            return 'male_disgusted'\n",
    "        elif item[:2]=='su':\n",
    "            return 'male_surprised'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos Arquivos de Áudio\n",
    "\n",
    "Os arquivos de áudio estão no Titan, na pasta /media/datasets/PLN/Cap12/Tarefa4/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para os arquivos\n",
    "mylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop pela pasta e extrai o nome de cada arquivo\n",
    "for path, subdirs, files in os.walk('/media/datasets/PLN/Cap12/Tarefa4/dados'):\n",
    "    for name in files:\n",
    "        mylist.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dos Arquivos de Áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai o sampling_rate dos arquivos\n",
    "data, sampling_rate = librosa.load(mylist)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos arquivos\n",
    "sr,x = scipy.io.wavfile.read(mylist)\n",
    "nstep = int(sr * 0.01)\n",
    "nwin  = int(sr * 0.03)\n",
    "nfft = nwin\n",
    "window = np.hamming(nwin)\n",
    "nn = range(nwin, len(x), nstep)\n",
    "X = np.zeros( (len(nn), nfft//2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "for i,n in enumerate(nn):\n",
    "    xseg = x[n-nwin:n]\n",
    "    z = np.fft.fft(window * xseg, nfft)\n",
    "    X[i,:] = np.log(np.abs(z[:nfft//2]))\n",
    "\n",
    "plt.imshow(X.T, interpolation='nearest',\n",
    "    origin='lower',\n",
    "    aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de Features dos Arquivos de Áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataframe\n",
    "label = fetch_label.FetchLabel()\n",
    "df = pd.DataFrame(columns = ['feature','emotion'])\n",
    "bookmark=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para extração das features\n",
    "for index,y in enumerate(mylist):\n",
    "    X, sample_rate = librosa.load(y, res_type = 'kaiser_fast', duration = 3, sr = 22050*2, offset = 0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "    feature = mfccs\n",
    "    emotion = label.get_emotion(y)\n",
    "    df.loc[bookmark] = [feature, emotion]\n",
    "    bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(df['feature'].values.tolist())\n",
    "labelled_df = pd.concat([feature_df,df['emotion']], axis=1)\n",
    "df_cleaned = labelled_df.dropna(0)\n",
    "shuffled_df = df_cleaned.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_df = shuffled_df.loc[~shuffled_df['emotion'].isin(['male_neutral', \n",
    "                                                            'male_disgusted', \n",
    "                                                            'male_surprised', \n",
    "                                                            'female_neutral', \n",
    "                                                            'female_disgusted', \n",
    "                                                            'female_surprised'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(shuffled_df.drop('emotion', axis = 1), \n",
    "                                                    shuffled_df['emotion'], \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0, \n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificando Rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "np.save('labels/label_classes.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansão de Dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_exp = np.expand_dims(X_train, axis=2)\n",
    "x_test_exp = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção e Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 5, padding = 'same', input_shape = (x_train_exp.shape[1],1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5, padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size = (8)))\n",
    "model.add(Conv1D(128, 5, padding = 'same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5, padding = 'same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr = 0.0001, decay = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train_exp, \n",
    "                    y_train, \n",
    "                    batch_size = 512, \n",
    "                    epochs = 600, \n",
    "                    validation_data = [x_test_exp, y_test], \n",
    "                    callbacks = [plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model.evaluate(x_train_exp, y_train, verbose=0)\n",
    "test_result = model.evaluate(x_test_exp, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train acc\",\"%s: %.2f%%\" % (model.metrics_names[1], train_result[1]*100))\n",
    "print(\"train acc\",\"%s: %.2f%%\" % (model.metrics_names[1], test_result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_exp, batch_size=512, verbose=1)\n",
    "preds_mod = preds.argmax(axis=1)\n",
    "preds_flat = preds_mod.astype(int).flatten()\n",
    "preds_transformed = (lb.inverse_transform((preds_flat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'predictedvalues': preds_transformed})\n",
    "actual_values = y_test.argmax(axis=1)\n",
    "actual_values_mod = actual_values.astype(int).flatten()\n",
    "actual_values_mod_transformed = (lb.inverse_transform((actual_values_mod)))\n",
    "actual_df = pd.DataFrame({'actualvalues': actual_values_mod_transformed})\n",
    "final_df = actual_df.join(pred_df)\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'detecta_emotion.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Modelo salvo em %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na Parte 3 usaremos o modelo treinado para detectar a emoção em arquivos de áudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
